{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFJQdrHdh8Q2zroKFgqor5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import required libraries"
      ],
      "metadata": {
        "id": "CdhRkoivNGbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "vxIFknEwNH5m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mount google drive because my data is stored there"
      ],
      "metadata": {
        "id": "qv4laVIMNLsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/archive/Training'\n",
        "test_dir = '/content/drive/MyDrive/archive/Testing'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSd0RGcqNVRm",
        "outputId": "a6bb0b09-6b4f-490a-ff39-1e71552efe29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load and preprocess images"
      ],
      "metadata": {
        "id": "XRa1WsWlPF7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)  # Adjust the size according to your requirements\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and preprocessing for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data preprocessing for the test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Loading and augmenting the training images\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Loading the test images\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsUkfC7SNzXg",
        "outputId": "7b00c938-20e9-43b5-9eca-655e03ca3d10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2870 images belonging to 4 classes.\n",
            "Found 394 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_size[0], image_size[1], 3)\n",
        ")\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGR8xUV2ToGt",
        "outputId": "be505b60-f913-401c-88c0-1043bbba330b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 8196      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,595,908\n",
            "Trainable params: 23,542,788\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "epochs = 10  # Adjust the number of epochs as needed\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVPoRqTOTufH",
        "outputId": "abdeac64-5a0e-4d5a-908e-0fcd16469fd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 2699s 30s/step - loss: 0.8490 - accuracy: 0.7181 - val_loss: 122.9827 - val_accuracy: 0.2919\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 2506s 28s/step - loss: 0.6122 - accuracy: 0.7889 - val_loss: 1.8160 - val_accuracy: 0.2944\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 2519s 28s/step - loss: 0.3793 - accuracy: 0.8624 - val_loss: 1.4194 - val_accuracy: 0.2690\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 2485s 28s/step - loss: 0.3241 - accuracy: 0.8861 - val_loss: 1.7479 - val_accuracy: 0.2970\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 2540s 28s/step - loss: 0.2603 - accuracy: 0.9059 - val_loss: 5.0843 - val_accuracy: 0.2665\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 2507s 28s/step - loss: 0.2168 - accuracy: 0.9279 - val_loss: 2.2801 - val_accuracy: 0.2843\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 2556s 28s/step - loss: 0.2135 - accuracy: 0.9230 - val_loss: 4.1639 - val_accuracy: 0.2589\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 2544s 28s/step - loss: 0.2139 - accuracy: 0.9247 - val_loss: 1.6457 - val_accuracy: 0.3807\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 2530s 28s/step - loss: 0.1892 - accuracy: 0.9352 - val_loss: 5.3784 - val_accuracy: 0.2716\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 2589s 29s/step - loss: 0.1798 - accuracy: 0.9394 - val_loss: 4.5227 - val_accuracy: 0.2944\n"
          ]
        }
      ]
    }
  ]
}